{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+----------------+--------------+------------+-----+\n",
      "|customerID|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|   MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|   PaymentMethod|MonthlyCharges|TotalCharges|Churn|\n",
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+----------------+--------------+------------+-----+\n",
      "|7590-VHVEG|Female|            0|    Yes|        No|   1.0|          No|No phone service|            DSL|            No|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|Electronic check|         29.85|       29.85|   No|\n",
      "|5575-GNVDE|  Male|            0|     No|        No|  34.0|         Yes|              No|            DSL|           Yes|          No|             Yes|         No|         No|             No|      One year|              No|    Mailed check|         56.95|      1889.5|   No|\n",
      "|3668-QPYBK|  Male|            0|     No|        No|   2.0|         Yes|              No|            DSL|           Yes|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|    Mailed check|         53.85|      108.15|  Yes|\n",
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+----------------+--------------+------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Load the data\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# s3_bucket = os.environ.get('S3_BUCKET', \"s3a://ml-field/demo/wine/\")\n",
    "# s3_bucket_region = os.environ.get('S3_BUCKET_REGION', \"us-west-2\")\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Telco Data Set\")\\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.hadoop.yarn.resourcemanager.principal\",\"u_001\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.s3guard.ddb.region\",\"us-east-1\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "telco_data_raw = spark.sql(\"SELECT * FROM `default`.`telco_churn`\")\n",
    "telco_data_raw.show(3) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|Churn|count(1)|\n",
      "+-----+--------+\n",
      "| null|      11|\n",
      "|   No|    5163|\n",
      "|  Yes|    1869|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ### Basic DataFrame operations\n",
    "# Dataframes essentially allow you to express sql-like statements. \n",
    "# We can filter, count, and so on. \n",
    "# Documentation - (http://spark.apache.org/docs/latest/sql-programming-guide.html#dataframe-operations)\n",
    "\n",
    "\"number of lines in dataset : {:d}\".format(telco_data_raw.count())\n",
    "\n",
    "# ### Spark SQL - manipulate data as if it was a table \n",
    "telco_data_raw.createOrReplaceTempView(\"telco\")\n",
    "spark.sql(\"select distinct(Churn), count(*) from telco GROUP BY Churn\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ### Remove invalid data\n",
    "# telco_data = telco_data_raw.filter(telco_data_raw.Churn != \"Yes\")\n",
    "# total_customers = telco_data.count()\n",
    "# churned_customers = telco_data.filter(wine_data.Churn == 'Excellent').count()\n",
    "# non_churned_customers = wine_data.filter(wine_data.Quality == 'Poor').count()\n",
    "\n",
    "# \"Wines total: {}, Good : {}, Poor : {}\".format(total_wines,good_wines,poor_wines )\n",
    "\n",
    "\n",
    "# # # 2. Data visualisation ( using mathplotlib and Seaborn)\n",
    "# # ## Feature Visualization\n",
    "# # \n",
    "# # The data vizualization workflow for large data sets is usually:\n",
    "# # \n",
    "# # * Sample data so it fits in memory on a single machine.\n",
    "# # * Examine single variable distributions.\n",
    "# # * Examine joint distributions and correlations.\n",
    "# # * Look for other types of relationships.\n",
    "# # \n",
    "# # [DataFrame#sample() documentation](http://people.apache.org/~pwendell/spark-releases/spark-1.5.0-rc1-docs/api/python/pyspark.sql.html#pyspark.sql.DataFrame.sample)\n",
    "\n",
    "# # ### Note: toPandas() => brings data localy !!!\n",
    "# sample_data = wine_data.sample(False, 0.5, 83).toPandas()\n",
    "# sample_data.transpose().head(21)\n",
    "\n",
    "# spark.stop()\n",
    "\n",
    "\n",
    "# # ## Feature Distributions\n",
    "# # \n",
    "# # We want to examine the distribution of our features, so start with them one at a time.\n",
    "# # \n",
    "# # Seaborn has a standard function called [dist()](http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.distplot.html#seaborn.distplot) that allows us to easily examine the distribution of a column of a pandas dataframe or a numpy array.\n",
    "\n",
    "# get_ipython().magic(u'matplotlib inline')\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sb\n",
    "\n",
    "# sb.distplot(sample_data['Alcohol'], kde=False)\n",
    "\n",
    "# # We can examine feature differences in the distribution of our features when we condition (split) our data.\n",
    "# # \n",
    "# # [BoxPlot docs](http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.boxplot.html)\n",
    "\n",
    "\n",
    "# sb.boxplot(x=\"Quality\", y=\"Alcohol\", data=sample_data)\n",
    "\n",
    "# # ## Joint Distributions\n",
    "# # \n",
    "# # Looking at joint distributions of data can also tell us a lot, particularly about redundant features. [Seaborn's PairPlot](http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.pairplot.html#seaborn.pairplot) let's us look at joint distributions for many variables at once.\n",
    "\n",
    "\n",
    "# example_numeric_data = sample_data[[\"fixedAcidity\", \"volatileAcidity\",\n",
    "#                                        \"citricAcid\", \"residualSugar\", \"Quality\"]]\n",
    "# sb.pairplot(example_numeric_data, hue=\"Quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
